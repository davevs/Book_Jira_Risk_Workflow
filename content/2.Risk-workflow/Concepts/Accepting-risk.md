### Accepting risk

Accepting risk is always a topic of discussion, mostly caused by lack of information. The JIRA Workflow aims to make this process more objective and pragmatic.

Risks can be accepted for a variety of reasons:

  * the system containing the risk will be decommissioned in the short term, and does not handle or process sensitive information
  * the risk can only occur under very specific circumstances 
  * the cost of fixing (both money and other resources) is much higher than the cost of fixing operational issues  
  * the business is okay with the probability of occurrence and its financial/commercial impact
  * the system is still under development and it is not live
  * the assets managed/exposed by the affected risks are not that important
  * the risk represents the current state of affairs and a significant effort would be required to change it

Risks should never be accepted for issues that

  * threaten the operational existence of the company (e.g. losing a banking license)
  * have significant financial impact (e.g. costs, fines due to data leaks)
  * have significant business impact (e.g. losing customers)
  * greatly impact the company's reputation (e.g. front page news)

Not being attacked is both a blessing and a curse. It's a blessing for a company that has not gone through the pain of an attack, but a curse because it is easy to gain a false sense of security.

The real challenge for companies that have NOT been attacked properly, or publicly, and don't have an institutional memory of those incidents, is to be able to quantify these risks in real business, financial, and reputational terms.

This is why exploits are so important for companies that don't have good internal references (or case studies) on why secure applications matter.

As one staff member or manager accepts risk on behalf of his boss, and this action is replicated throughout a company, all the way to the CTO, risks are accumulated. If risks are accepted throughout the management levels of a company, then responsibility should be borne in a similar way if things go wrong.  Developers should be able to ensure that it is their manager who will get fired. That manager should make sure that his boss will get fired, and so on, all the way to the CTO and the CISO.

 
  
  * business owners (or who controls the development pipeline) make large number of decisions with very little side effects
  
  * add explanation of why pollution is a much better analogy than 'Technical Debt' (in measuring the side effects of coding and management decisions).
    * Risk is a nice way to measure this polution
  * _"...you are already being played in this game, so you might as well expose the game and tilt the rules in your favour..."_
  *
  
There is a video by Host Unknown, that lays out the consequences of thoughtlessly accepting risk. It is a comic piece, but with a very serious message. ([Host Unknown presents: Accepted the Risk](https://www.youtube.com/watch?v=9IG3zqvUqJY))
